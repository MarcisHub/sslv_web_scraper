""" This module is processing HTTP get requsts
to scrape property data form ss.lv """


from datetime import datetime
import logging
import logging.handlers as handlers
from logging.handlers import RotatingFileHandler
import os
import sys
import uvicorn
from fastapi import BackgroundTasks, FastAPI
from app.wsmodules.file_downloader import download_latest_lambda_file
from app.wsmodules.web_scraper import scrape_website
from app.wsmodules.data_format_changer import data_formater_main
from app.wsmodules.df_cleaner import df_cleaner_main
from app.wsmodules.db_worker import db_worker_main
from app.wsmodules.analytics import analytics_main
from app.wsmodules.pdf_creator import pdf_creator_main
from app.wsmodules.sendgrid_mailer import sendgrid_mailer_main


log = logging.getLogger('fastapi')
log.setLevel(logging.INFO)
fastapi_log_format = logging.Formatter(
    "%(asctime)s [%(threadName)-12.12s]"
    " [%(levelname)-5.5s] : %(funcName)s:"
    " %(lineno)d: %(message)s")

ch = logging.StreamHandler(sys.stdout)
ch.setFormatter(fastapi_log_format)
log.addHandler(ch)

fh = handlers.RotatingFileHandler('fastapi.log',
                                  maxBytes=(1048576*5),
                                  backupCount=7)
fh.setFormatter(fastapi_log_format)
log.addHandler(fh)

app = FastAPI()
CITY_NAME = 'Ogre'


@app.get("/")
def home():
    """Test enpoint to verify if fast-api is live"""
    return {"FastAPI server is ready !!!"}


@app.get("/run-task/{city}")
async def run_long_task(city: str, background_tasks: BackgroundTasks):
    """ Endpint to trigger scrape, format and insert data in DB"""
    log.info("Recieved GET request to start scraping job for Ogre city")
    background_tasks.add_task(download_latest_lambda_file)
    todays_cloud_data_file_exist = check_today_cloud_data_file_exist()

    if todays_cloud_data_file_exist is True:
        last_cloud_file_name = get_todays_cloud_data_file_name()
        log.info("Cloud scraper module data file: %s "
                 "found will be used in "
                 " data_formater_module ", last_cloud_file_name)
        log.info(
            "Sent data_formater_main task to background: using cloud ws file")
        background_tasks.add_task(data_formater_main)
        log.info(
            "Sent df_cleaner_main task to background: using cloud ws file")
        background_tasks.add_task(df_cleaner_main)
        log.info("Sent db_worker_main task to background: using cloud ws file")
        background_tasks.add_task(db_worker_main)
        log.info("Sent analytics_main task to background: using cloud ws file")
        background_tasks.add_task(analytics_main)
        log.info(
            "Sent sendgrid_mailer task to background: using cloud ws file")
        background_tasks.add_task(pdf_creator_main)
        log.info("Sent pdf_creator task to background: using cloud ws file ")
        background_tasks.add_task(sendgrid_mailer_main)
        log.info("Send all taks to background completed")
        return {
            "message": "FAST_API: scrape Ogre city sent as "
                       " background task using cloud ws file"
        }

    lst_run_state = check_lst_run_state(CITY_NAME)
    if lst_run_state:
        log.info("EXIT: will not call ws_worker "
                 "module because task was run last 24H")
        return {"message": "Local scraper job already has run,"
                           " in last 24H will not run today again"}

    log.info(
        "Sent scrape_website task to background: will create local ws file")
    background_tasks.add_task(scrape_website)
    log.info("Sent data_formater_main task to background:")
    background_tasks.add_task(data_formater_main)
    log.info("Sent df_cleaner_main task to background:")
    background_tasks.add_task(df_cleaner_main)
    log.info("Sent db_worker_main task to background:")
    background_tasks.add_task(db_worker_main)
    log.info("Sent analytics_main task to background:")
    background_tasks.add_task(analytics_main)
    log.info("Sent sendgrid_mailer task to background:")
    background_tasks.add_task(pdf_creator_main)
    log.info("Sent pdf_creator task to background:")
    background_tasks.add_task(sendgrid_mailer_main)
    log.info("Send all taks to background completed")
    return {
        "message": "FAST_API: scrape Ogre city sent as "
                   "background task local scrape job will be triggered"
    }


def check_today_cloud_data_file_exist() -> bool:
    """Checks if file Ogre-raw-data-report-YYYY-MM-DDTMM-HH-SS.txt
    which was generated by AWS lambda scraper and downloaded from S3 bucket
    exist in local_lambda_raw_scraped_datafolder with todays date"""
    cloud_file_folder = "local_lambda_raw_scraped_data"
    todays_date = datetime.today().strftime('%Y-%m-%d')
    log.info(f"Searching for cloud files with todays date: {todays_date}")
    if not os.path.exists(cloud_file_folder):
        log.error(f'Folder {cloud_file_folder}'
                  ' does not exist creating empty folder')
        os.makedirs(cloud_file_folder)
    # Uncoment below once cloud file usage in data_formater_main is implemented
    # for file_name in os.listdir(cloud_file_folder):
    #     if todays_date in file_name:
    #         log.info('File %s containing today'
    #                  ' date %s found, ', file_name, todays_date)
    #         return True
    log.info('File containing today date %s was not found,'
             ' will try to find local craper file', todays_date)
    return False


def get_todays_cloud_data_file_name() -> str:
    """Checks if file Ogre-raw-data-report-YYYY-MM-DDTMM-HH-SS.txt
    which was generated by AWS lambda scraper and
    downloaded from S3 bucket exist in local_lambda_raw_scraped_data
    folder with todays date and returns file name"""

    cloud_file_folder = "local_lambda_raw_scraped_data"
    todays_date = datetime.today().strftime('%Y-%m-%d')
    log.info(
        f"Searching for cloud scraper file with todays date: {todays_date}")
    if not os.path.exists(cloud_file_folder):
        log.error(
            f'Folder {cloud_file_folder} does not exist creating empty folder')
        os.makedirs(cloud_file_folder)
    for file_name in os.listdir(cloud_file_folder):
        if todays_date in file_name:
            log.info('File %s containing today date'
                     '%s found, ', file_name, todays_date)
            return file_name


def check_lst_run_state(city_name) -> bool:
    """
    Returns true if Ogre-raw-data-report-YYYY-MM-DD.txt
    with todays date exists.
    """
    todays_date = datetime.today().strftime('%Y-%m-%d')
    target_filename = city_name + '-raw-data-report-' + todays_date + '.txt'
    if not os.path.exists('data'):
        os.makedirs('data')
    for filename in os.listdir("data"):
        if filename == target_filename:
            log.info('File %s found, task for '
                     'Ogre has run today', target_filename)
            return True
    log.info('File %s was not found, running '
             ' scrape task for Ogre city', target_filename)
    return False


if __name__ == "__main__":
    uvicorn.run(app)
